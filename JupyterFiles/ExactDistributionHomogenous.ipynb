{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simply importing the needed classes.\n",
    "Notice the AAAx and BBBx dicts are optimal guesses for a few Q curves as interpolated from our CDS bootstrapping class\n",
    "This computation is expensive and does not always converge for our intial guess of x0Vas so I have copied them here to save some computations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "import math\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from random import shuffle\n",
    "import random\n",
    "import fractions\n",
    "\n",
    "AAAx={'3M': [1.0015824271136229, 0.07118430651357378, -0.16068883479216692, 0.0073983085859183105, 3.1083459253964976, -4.971784090683851, -0.4774848528659512, -0.10058722679096088, -0.32595880089361595, 1.2498165670968577, 3.4947594489126534, 0.7693240320536217, 1.3561952580367567, 6.371501575362355, 1.5717830330107334, 3.0431872392927932], '6M': [0.6253740242837578, 0.07187788235360676, 0.002756754524306165, 0.0007534565001362353, -1.9788331302293565, 1.3633887485139464, 5.119926963331688, 3.1051517704782445, 0.7634682512381973, -0.2440315461962444, -1.625294304111004, 1.1807892914373608, 1.5803472042649411, 2.2546258881657137, -0.6220529111275982, -3.918280795179225], '1Y': [0.02268430209412819, 0.12335315163831377, 0.0019492996048123179, 0.001628657655447479, 2.012129584631548, -0.14425637029306565, 3.0201995002610156, 2.147972541679386, -0.5128642176120338, 2.2747902950169627, -0.20546619851504466, 1.5945520333717365, 1.1372771020777144, 3.5153776822797216, 0.9602982736891876, -2.470770239032655], '3Y': [26.4868013103451, 0.10123386920113561, 0.007172027822595987, -0.0011729920248976869, 4.671838150691669, 2.0943942967130518, 1.8784163354679428, 2.829205309274365, 0.6419078923238758, 1.9913439793507237, 0.9155288227819725, 0.2038138762167537, 5.345533516522538, 3.7619427230742546, 0.1152302416309914, 2.657152673978014]}\n",
    "BBBx={'3M': [2.2676030271568077, 0.06869592728485677, -0.002415215219504258, 0.0010910153202821262, 2.076053981582788, -2.4830012835412374, 1.4792817746843325, 2.227857983492404, -0.3936126755070518, -0.16392645500488395, 1.285584627035015, 3.041436386446073, 3.2291187114730233, 3.3449348319234886, -2.054285553987237, 0.906769966943711]}\n",
    "class MC_Vasicek_Sim(object):\n",
    "    \"\"\" Monte Carlo simulator for interest rates under the Vasicek \n",
    "    model.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    kappa (float): Vasicek perameter: 'speed of reversion'.\n",
    "    theta (float): Vasicek perameter: 'long term mean level'.\n",
    "    sigma (float): Vasicek perameter: 'volatility'\n",
    "    r0 (float): Vasicek perameter: 'initial value'.\n",
    "    t_step (float): The time difference between the 'steps' in the \n",
    "        simulation. Represents 'dt' in the Vasicek model. Should always\n",
    "        be set to 1 day.\n",
    "    simNumber (int): The number of times the simulation is to execute.\n",
    "    datelist (list): A list of strings that are date-formatted (e.g.\n",
    "        '2016-10-17').\n",
    "    datelistlong (list): A list of days between (and including) \n",
    "        min(datelist) and max(datelist). Each element is of type \n",
    "        datetime.date.\n",
    "    ntimes (list):  The length of datelistlong.\n",
    "    libor (pandas DataFrame): A (1 + ntimes, simNumber) shaped array \n",
    "        that  contains the simulated discount curves. The zeroth column \n",
    "        contains the mean curve. The type of each element is \n",
    "        numpy.float64. The row labels are dates corresponding to\n",
    "        nodes in the simulation.\n",
    "    smallLibor (pandas DataFrame): A matrix subset of the \n",
    "        libor array. But it only contains rows corresponding to the \n",
    "        dates in `datelist` instead of `datelistlong`.\n",
    "    liborAvg (numpy ndarray): A vector containing the mean\n",
    "        simulated libor values. It is also the zeroth column of \n",
    "        `libor`.\n",
    "    \"\"\"\n",
    "    def __init__(self, datelist,x, simNumber,t_step):\n",
    "\n",
    "        \"\"\"Perameters\n",
    "        ----------\n",
    "        datelist (list): A list of strimgs that are date-formatted,\n",
    "            e.g. '2012-04-16'.\n",
    "        x (tuple): A 4-tuple containing the Vasicek SDE perameters:\n",
    "            kappa, theta, sigma, r0.\n",
    "        simNumber (int): The number of simulations that is to be \n",
    "            executed.\n",
    "        \"\"\"\n",
    "    #SDE parameters - Vasicek SDE\n",
    "    # dr(t) = k(θ − r(t))dt + σdW(t)\n",
    "        self.kappa = x[0]\n",
    "        self.theta = x[1]\n",
    "        self.sigma = x[2]\n",
    "        self.r0 = x[3]\n",
    "        self.simNumber = simNumber\n",
    "        self.t_step = t_step\n",
    "    #internal representation of times series - integer multiples of t_step\n",
    "        self.datelist = datelist\n",
    "    #creation of a fine grid for Monte Carlo integration\n",
    "        #Create fine date grid for SDE integration\n",
    "        minDay = min(datelist)\n",
    "        maxDay = max(datelist)\n",
    "        self.datelistlong = pd.date_range(minDay, maxDay).tolist()\n",
    "        self.datelistlong = [x.date() for x in self.datelistlong]\n",
    "        self.ntimes = len(self.datelistlong)\n",
    "        self.libor=[]\n",
    "        self.smallLibor = []\n",
    "        self.liborAvg=pd.DataFrame()\n",
    "        \n",
    "    def getLibor(self):\n",
    "        \"\"\"Executes the simulations and returns the simulated libor curves.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        A large 2D pandoc DataFrame. Each column represents a simulated value of\n",
    "        the libor curve at a given point in time. Each row corresponds to a\n",
    "        date in `datelonglist`. The zeroth column contains the mean value of\n",
    "        the simulated libor curves. The row labels are the elements of \n",
    "        datelonglist.\n",
    "        \"\"\"\n",
    "\n",
    "        rd = np.random.standard_normal((self.ntimes,self.simNumber))   # array of numbers for the number of samples\n",
    "        r = np.zeros(np.shape(rd))\n",
    "        nrows = np.shape(rd)[0]\n",
    "        sigmaDT = self.sigma* np.sqrt(self.t_step)\n",
    "        #calculate r(t)\n",
    "        r[1,:] = self.r0+r[1,:]\n",
    "        for i in np.arange(2,nrows):\n",
    "            r[i,:] = r[i-1,:]+ self.kappa*(self.theta-r[i-1,:])*self.t_step + sigmaDT*rd[i,:]\n",
    "        #calculate integral(r(s)ds)\n",
    "        integralR = r.cumsum(axis=0)*self.t_step\n",
    "        #calculate Libor\n",
    "        self.libor = np.exp(-integralR)\n",
    "        self.liborAvg=np.average(self.libor,axis=1)\n",
    "        self.libor=np.c_[self.liborAvg,self.libor]\n",
    "        self.libor = pd.DataFrame(self.libor,index=self.datelistlong)\n",
    "        return self.libor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "genUnderlyings generates a stripped down version of an underlying with the important information stored in a tuple.\n",
    "The computation later gets very slow the larger the number of underlyings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def genUnderlyings(notional,R,start,freq,quality,number):\n",
    "    out=[]\n",
    "    for i in range(0,number):\n",
    "        out.append((notional,start,freq,quality,R))\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Scheduler(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def extractDelay(self, freq):\n",
    "        if type(freq) == list:\n",
    "            freq = freq[0]\n",
    "        if (freq == 'Date'): return relativedelta(days=+ 1)\n",
    "        x = self.only_numerics(freq)\n",
    "        if (x == ''):\n",
    "            freqValue = 100\n",
    "        else:\n",
    "            freqValue = np.int(x)\n",
    "        if (freq.upper().find('D') != -1): delta = relativedelta(days=+  freqValue)\n",
    "        if (freq.upper().find('W') != -1): delta = relativedelta(weeks=+  freqValue)\n",
    "        if (freq.find('M') != -1): delta = relativedelta(months=+ freqValue)\n",
    "        if (freq.find('Y') != -1): delta = relativedelta(years=+ freqValue)\n",
    "        if (freq.find('ZERO') != -1): delta = relativedelta(years=+ freqValue)\n",
    "        return delta\n",
    "    def only_numerics(self, seq):\n",
    "        seq_type = type(seq)\n",
    "        return seq_type().join(filter(seq_type.isdigit, seq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The book calls this type of function an exact function. The underlying principle is that we can build the conditional loss distribution by remembering the fact that when the underlying credits are independent we have a natural recursive algorithim to calculate. Also notice, that for base cases if 0 credits default in a portfolio of 0 then the probability of this event is set to 1. In a portfolio of 0 credits and the probability of more than 1 default occuring is 0. \n",
    "Naturally, the probability that the portfolio survives is simply the multiplication of the underlying survival probabilities. So the rest is easily computed by recursion. \n",
    "\n",
    "In this function we used our Monte Carlo simulator to give us the Q(0,Maturity) for each of the underlyings. Then \n",
    "f(k,j) calculates the probability of k defaults in a portfolio of j credits under our homogenous loss. Although this is very easily extendable to inhomogenous cases as the book points out using a greatest common denomenator. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ExactFunc(object):\n",
    "    \n",
    "    def __init__(self,start,underlyings):\n",
    "        \n",
    "        myScheduler=Scheduler()\n",
    "        myDelays=[]\n",
    "        freqs=['3M','6M','1Y','3Y']\n",
    "        for i in range(0,len(freqs)):\n",
    "            myDelays.append(myScheduler.extractDelay(freqs[i]))\n",
    "        AAA={}\n",
    "        for i in range(0,len(freqs)):\n",
    "            vas=MC_Vasicek_Sim(x=AAAx[freqs[i]],datelist=[start,myDelays[i]+start],t_step=1/365.,simNumber=500)\n",
    "            AAA[freqs[i]]=vas.getLibor()[0].loc[myDelays[i]+start]\n",
    "        \n",
    "        BBB={'3M': MC_Vasicek_Sim(x=BBBx[freqs[0]],datelist=[start,myDelays[0]+start],t_step=1/365.,simNumber=500).getLibor()[0].loc[myDelays[0]+start]}\n",
    "        self.probs={'AAA': AAA, 'BBB':BBB}\n",
    "        self.underlyings=underlyings\n",
    "        \n",
    "    def f(self,k,j):\n",
    "        ''' \n",
    "        The recursion relation for the homogenous portfolio \n",
    "        takes in k: an int for numer of defaults \n",
    "        and j: number of underlyings you want to consider in the calculation k cannnot be greater than j\n",
    "        \n",
    "        \n",
    "        \n",
    "        '''\n",
    "        if(j==0 and k==0):\n",
    "            return 1\n",
    "        if(j==0 and k>0):\n",
    "            return 0\n",
    "        if(k==0 and j>0):\n",
    "            return self.f(k,j-1)*self.probs[self.underlyings[j][3]][self.underlyings[j][2]]\n",
    "        else:\n",
    "            return self.f(k,j-1)*(self.probs[self.underlyings[j][3]][self.underlyings[j][2]])+self.f(k-1,j-1)*(1-self.probs[self.underlyings[j][3]][self.underlyings[j][2]])\n",
    "    '''\n",
    "    Helper functions \n",
    "    \n",
    "    '''\n",
    "    def gcd(self,x, y):\n",
    "        while y != 0:\n",
    "            (x, y) = (y, x % y)\n",
    "        return x\n",
    "        \n",
    "    def totalGCD(self):\n",
    "        g=(1-self.underlyings[0][4])*self.underlyings[0][0]\n",
    "        for i in range(1,len(self.underlyings)):\n",
    "            g=self.gcd(g,((1-self.underlyings[i][4])*self.underlyings[i][0]))\n",
    "        return g\n",
    "\n",
    "    def getLossVec(self):\n",
    "        g=self.totalGCD()\n",
    "        n=[]\n",
    "        for i in range(0,len(self.underlyings)):\n",
    "            n.append(((1-self.underlyings[i][4])*self.underlyings[i][0])/g)\n",
    "        return n\n",
    "    \n",
    "    def fprime(self,k,j,vec):\n",
    "        '''\n",
    "        recursion relation for inhomogenous portfolio takes \n",
    "        k an int representing number of defaulted credits\n",
    "        j an int representing number of underlyings we wish to consider\n",
    "        vec a list of length of underlyings with the underlyings Loss given default scaled by gcd so\n",
    "        each entry is an int\n",
    "        '''\n",
    "        if(j==0 and k==0):\n",
    "            return 1\n",
    "        if(j==0 and k>0):\n",
    "            return 0\n",
    "        if(0<=k and vec[j]>k):\n",
    "            return self.fprime(k,j-1,vec)*self.probs[self.underlyings[j][3]][self.underlyings[j][2]]\n",
    "        if(vec[j]<= k ):\n",
    "            return self.fprime(k,j-1,vec)*(self.probs[self.underlyings[j][3]][self.underlyings[j][2]])+self.fprime(k-vec[j],j-1,vec)*(1-self.probs[self.underlyings[j][3]][self.underlyings[j][2]])\n",
    "       \n",
    "    '''\n",
    "    methods to get number of defaults required to break tranche upperstrike not used just informative\n",
    "\n",
    "\n",
    "\n",
    "    '''\n",
    "    def getTrancheNumb(self,K):\n",
    "        sum=np.array(self.getLossVec()).sum()\n",
    "        losses=self.getLossVec()\n",
    "        totalLoss=0\n",
    "        for i in range(0,len(losses)):\n",
    "            totalLoss=totalLoss+losses[i]/sum\n",
    "            if(totalLoss >= K):\n",
    "                return i\n",
    "\n",
    "    def threshold(self,K):\n",
    "        sum=np.array(self.getLossVec()).sum()\n",
    "        return math.floor(sum*K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trim_start=date(2005,1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "credits=genUnderlyings(1,.4,trim_start,'3M','AAA',10)+genUnderlyings(1,.4,trim_start,'6M','AAA',10)+genUnderlyings(1,.4,trim_start,'1Y','AAA',10)+genUnderlyings(1,.4,trim_start,'3Y','AAA',5)+genUnderlyings(1,.4,trim_start,'3M','BBB',5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ex=ExactFunc(underlyings=credits,start=trim_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y=[]\n",
    "x=[]\n",
    "for i in range(0,7):\n",
    "    y.append(ex.f(i,len(ex.underlyings)-1))\n",
    "    x.append(i*.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.xlabel(\"Portfolio Loss %\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.bar(x,y)\n",
    "plt.savefig('ffunc.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are inserting a list of underlyings with a random recovery. After some expirementation the random recovery\n",
    "can cause the sum of the losses of the credits to get extremely large. There is a discussion in the book about this issue. So we consider only a minimal case where a few credits have recovery different than .4. But now we will look at the loss in terms of \"loss units.\" We create a method to determine the number of units lost out of the total will breach the upper strike. So we can limit our iterations of defaults to just these numbers. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "randR=genUnderlyings(100,.4,trim_start,'3M','AAA',20)+genUnderlyings(100,.4,trim_start,'6M','AAA',10)+genUnderlyings(100,.4,trim_start,'1Y','AAA',10)+genUnderlyings(100,round(random.uniform(.25,.5),2),trim_start,'3Y','AAA',1)+genUnderlyings(100,.3,trim_start,'3M','BBB',1)\n",
    "shuffle(randR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exactRandR=ExactFunc(underlyings=randR,start=trim_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n"
     ]
    }
   ],
   "source": [
    "z=[]\n",
    "w=[]\n",
    "for i in range(0,exactRandR.threshold(.1)):\n",
    "    z.append(exactRandR.fprime(i,len(exactRandR.underlyings)-1,exactRandR.getLossVec()))\n",
    "    if(i %10 ==0):\n",
    "        print(i)\n",
    "    w.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.xlabel(\"Portfolio Loss In Dollars\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.bar(w,z)\n",
    "plt.savefig('fprime.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
